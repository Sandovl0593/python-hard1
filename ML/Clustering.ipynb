{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_kmeans(X: np.ndarray, k, toler=0.001):\n",
    "    # centroids is a k x d matrix, where its values are the centroids of the clusters\n",
    "    # C_i is a n x 1 vector, where its values are the cluster index of each point in X\n",
    "    n = X.shape[0]\n",
    "    # initialize random centroids\n",
    "    centroids = X[np.random.choice(n, k, replace=False)]\n",
    "    \n",
    "    # until the centroids do not change significantly (dist(\\micron_i^{t+1}, \\micron_i^t) < toler)\n",
    "    while True:\n",
    "        # for each point x_j in X, assign it to the closest centroid \\micron_i\n",
    "        C_i = np.argmin(np.linalg.norm(X[:, None] - centroids, axis=-1), axis=-1)\n",
    "        # we use argmin to get the index of the closest centroid\n",
    "\n",
    "        # for each cluster C_i, update the centroid \\micron_i as the mean of all points assigned to it\n",
    "        micron_new = np.array([X[C_i == i].mean(axis=0) for i in range(k)])\n",
    "\n",
    "        # if the centroids do not change significantly, break\n",
    "        if np.linalg.norm(micron_new - centroids) < toler:\n",
    "            break\n",
    "        centroids = micron_new\n",
    "\n",
    "    return centroids, C_i "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans++ is a variant of kmeans that initializes the centroids in a more intelligent way\n",
    "# the first centroid is chosen uniformly at random from the data points\n",
    "\n",
    "def kmeans_plus_plus(X: np.ndarray, k, toler=0.001):\n",
    "    n = X.shape[0]\n",
    "    # initialize centroids with first point\n",
    "    centroids = [X[np.random.choice(n)]]\n",
    "    \n",
    "    for _ in range(k-1):\n",
    "        # for each point x_j in X, calculate the distance to the closest centroid\n",
    "        dist = np.linalg.norm(X[:, None] - centroids, axis=-1).min(axis=-1)\n",
    "        # calculate the probability of each point to be chosen as the next centroid\n",
    "        prob = dist**2 / (dist**2).sum()\n",
    "        # choose the next centroid\n",
    "        centroids.append(X[np.random.choice(n, p=prob)])\n",
    "    \n",
    "    centroids = np.array(centroids)\n",
    "\n",
    "    # until the centroids do not change significantly (dist(\\micron_i^{t+1}, \\micron_i^t) < toler)\n",
    "    while True:\n",
    "        # for each point x_j in X, assign it to the closest centroid \\micron_i\n",
    "        C_i = np.argmin(np.linalg.norm(X[:, None] - centroids, axis=-1), axis=-1)\n",
    "        # we use argmin to get the index of the closest centroid\n",
    "\n",
    "        # for each cluster C_i, update the centroid \\micron_i as the mean of all points assigned to it\n",
    "        micron_new = np.array([X[C_i == i].mean(axis=0) for i in range(k)])\n",
    "\n",
    "        # if the centroids do not change significantly, break\n",
    "        if np.linalg.norm(micron_new - centroids) < toler:\n",
    "            break\n",
    "        centroids = micron_new\n",
    "\n",
    "    return centroids, C_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MeanShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meanshift require a KDTREE to find the nearest neighbors\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "def meanshift(X: np.ndarray, bandwidth=0.5, toler=0.001):\n",
    "    n = X.shape[0]\n",
    "    # assign each data point y_i = x_i for all points in X\n",
    "    y = X.copy()\n",
    "    # build a KDTree to find the nearest neighbors\n",
    "    tree = KDTree(X)\n",
    "\n",
    "    while True:\n",
    "        # for each point y_i in X\n",
    "        for i in range(n):\n",
    "            # find the neighbors of y_i within a radius of bandwidth\n",
    "            neighbors = tree.query_radius(y[i][None], bandwidth)[0]\n",
    "            \n",
    "            # update y_i  using the Gaussian kernel, computing the new value y_i as the weighted mean of the neighbors\n",
    "            kernel_j = np.exp(-np.linalg.norm(y[neighbors] - y[i], axis=-1)**2 / (2 * bandwidth**2))\n",
    "            y[i] = (kernel_j[:, None] * y[neighbors]).sum(axis=0) / kernel_j.sum()\n",
    "\n",
    "            # if the centroids do not change significantly, break\n",
    "        if np.linalg.norm(y - X) < toler:\n",
    "            break\n",
    "        X = y\n",
    "\n",
    "    #group points y_i that converge to the same mode into the same cluster\n",
    "    C_i = np.zeros(n, dtype=int)\n",
    "    for i in range(n):\n",
    "        C_i[i] = np.argmin(np.linalg.norm(y[i] - y, axis=-1))\n",
    "    # assign each point x_i to the corresponding cluster based on its converged value y_i\n",
    "    X = y\n",
    "    return C_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomerative Clustering (insecure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agglomerative construye un dendograma con los datos, en donde cada punto es un cluster y a medida que se van uniendo los clusters, se va formando un árbol.\n",
    "# def agglomerative(X: np.ndarray, metric='normal'):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisive Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divisive clustering divide el dendograma en clusters más pequeños a partir de un punto de corte dado\n",
    "def DbisiveClustering(X: np.ndarray, var_tol=0.001):\n",
    "    n = X.shape[0]\n",
    "    # begin all data points in a single cluster: C = {X}\n",
    "    C = [X]\n",
    "    # while tha variance of the clusters is greater than a threshold\n",
    "    variance = [np.var(C_i, axis=0) for C_i in C]\n",
    "    while np.var(variance) > var_tol:\n",
    "        # choose the cluster C_max with the largest dissimilarity (example: highest variance)\n",
    "        C_max = np.argmax(variance)\n",
    "        # split C_max into two clusters C_i and C_j with a partitioning algorithm (kmeans)\n",
    "        _, C_i = general_kmeans(C[C_max], 2)\n",
    "        # update clusters C = C - {C_max} + {C_i, C_j}\n",
    "        C.pop(C_max)\n",
    "        C.append(C[C_max][C_i == 0])\n",
    "        C.append(C[C_max][C_i == 1])\n",
    "        # update variance\n",
    "        variance = [np.var(C_i, axis=0) for C_i in C]\n",
    "\n",
    "    # assign each point x_i to the corresponding cluster based on the cluster it belongs to\n",
    "    C_i = np.zeros(n, dtype=int)\n",
    "    for i, C_i_ in enumerate(C):\n",
    "        C_i[C_i_] = i\n",
    "    return C_i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral clustering aplica kmeans a una representación de los datos en un espacio de menor dimensión a partir de la matriz de afinidad\n",
    "def SpectralClustering(afinity: np.ndarray, k):\n",
    "    # construct degree matrix\n",
    "    D = np.diag(np.sum(afinity, axis=0))\n",
    "\n",
    "    # compute the Laplacian matrix\n",
    "    L = D - afinity\n",
    "\n",
    "    # computer the eigenvectors of the Laplacian matrix\n",
    "    eigvals, eigvecs = np.linalg.eigh(L)\n",
    "    # get k eigenvectors from the k smallest eigenvalues (sort them first)\n",
    "    X = eigvecs[:, np.argsort(eigvals)[:k]]\n",
    "\n",
    "    # normalize each row of X to have unit length\n",
    "    X /= np.linalg.norm(X, axis=-1)[:, None]\n",
    "\n",
    "    # apply kmeans to the rows of X into k clusters \n",
    "    _, C_i = general_kmeans(X, k, toler=0.001)\n",
    "\n",
    "    # assign the i-th node to the cluster corresponding to the i-th row of X\n",
    "    name_rows = np.argsort(eigvals)[:k] # sort indices of the k smallest eigenvalues\n",
    "    C_i = C_i[np.argsort(name_rows)] # sort the cluster indices to match the original order of the nodes\n",
    "    \n",
    "    return C_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cadena de Markov es un modelo de secuencia de eventos en que la probabilidad de que ocurra un evento depende del evento anterior\n",
    "# Markov Clustering: Utiliza una matriz de afinidad para construir una matriz de transición y simular un proceso de difusión en la red\n",
    "def MarkovClustering(afinity: np.ndarray, p=2, r=2):\n",
    "    \"p: power parameter, r: inflation parameter\"\n",
    "    # normalize the rows of the affinity matrix\n",
    "    afinity /= afinity.sum(axis=1)[:, None]\n",
    "\n",
    "    # repeat the following steps until convergence\n",
    "    while True:\n",
    "        # Expansion: raise the matrix to the power p\n",
    "        afinity = afinity ** p\n",
    "\n",
    "        # Inflation: raise each element to the power r and normalize the rows\n",
    "        afinity = (afinity ** r) / (afinity ** r).sum(axis=1)[:, None]\n",
    "\n",
    "        # if the matrix does not change significantly, break\n",
    "        if np.linalg.norm(afinity - afinity @ afinity) < 0.001:\n",
    "            break\n",
    "        \n",
    "    # group the rows of the matrix into clusters\n",
    "    C_i = np.argmax(afinity, axis=1)\n",
    "    return C_i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
